---
title: "Best Value Universities"
author: "Madeleine Jones, Audrey Himes, Hayden Ratliff"
date: "12/01/2021"
output: 
  html_document:
    toc: TRUE
    toc_float: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r}
library(tidyverse)
library(caret)
library(class)
library(plotly)
library(RColorBrewer)
library(ROCR)
library(MLmetrics)
library(ggpubr)
library(e1071)  # load all of the libraries needed for the lab
library(plotly)
library(htmltools)
library(devtools)
library(NbClust)
library(DT)
```

## Question and Background Information 
What are the best value colleges? We will be looking at tuition and other metrics such as graduation rates, etc to determine which colleges are the best value?

## Exploratory Data Analysis 
### Read and Clean the Data 
```{r}
data<- read.csv("/Users/mj/Desktop/2021 Fall/DS 3001/DS-3001/Final Project/College_Data.csv")  # reading in the data set 

data <- data %>% rename(College = X, AppsRecieved = Apps, AppsAccepted = Accept, NewStudentsEnrolled = Enroll, Top10Percent = Top10perc, Top25Percent = Top25perc, FullTimeUndergrads = F.Undergrad, PartTimeUndergrads = P.Undergrad, OutStateTuition = Outstate, RoomBoardCosts = Room.Board, BooksCost = Books, PersonalSpendings = Personal, FacultyPhDPercentage = PhD, FacultyTerminalPercentage = Terminal, StudentFacultyRatio = S.F.Ratio, DonatingAlumniPercentage = perc.alumni, ExpenditurePerStudent = Expend, GraduationRate = Grad.Rate)  # relabel the columns with more understandable names

data$Private <- as.factor(data$Private)

data$Private<-as.factor(ifelse(data$Private == "Yes",1,0))

data <- data[complete.cases(data), ]

data[which(data$GraduationRate > 100), "GraduationRate"] <- 100

str(data)
```

### Numeric Variable Correlations with Salary

```{r}
numeric <- names(select_if(data, is.numeric))  # select the column labels from the numeric columns
numericdata <- data[,numeric]  # create a table of the numeric data columns
tuition<- numericdata[,8]  # save salary as its own vector for comparison
numericvars <- numericdata[,-8]  # save other numeric variables in table for comparison

cors = data.frame(CorrelationWithTuition = apply(numericvars, 2, function(x) cor(tuition, x)))  # apply the correlation function to the salary vector and all columns of the numeric variable table to determine which variables are most correlated to salary
cors <- arrange(cors, -abs(CorrelationWithTuition))
datatable(cors)
```

The variables with the greatest correlation to tuition are those that will be the most informative of varying university quality based on price.  Therefore, the highly correlated variables will be best to cluster the data and determine which universities are the best value. The variables with strong correlations above 0.5, or below -0.5 are University Expenditure Per Student, Room and Board Costs, Graduation Rate, the Percentage of Alumni who Donate, the Percentage of Students in the Top 10% of their Class, and the Student to Faculty Ratio.  

Noting, however, that room and board is another cost to the student rather than an offering of the university similar to tuition, this metric will only be used in clustering, but will not be used in modeled when determining value,.  Therefore, the variables we will use to model the value of universities are Expenditure Per Student, Graduation Rate, the Percentage of Alumni who Donate, the Percentage of Students in the Top 10% of their Class, and the Student to Faculty Ratio.

## Methods 
In order to determine the patterns that exist among university attributes, we will use a k-means clustering algorithm.  K-means is an unsupervised algorithm in which clustering of data occurs by minimizing the variance, or distance, between intra-cluster data and maximizing the variance between inter-cluster data points.  With the k-means clustering algorithm, we will cluster universities into those that are of higher or lower quality.  Then, we will examine university tuitions to determine which universities are the "best value," with high quality and low tuition.

### Standardizing The Numeric Variables 
To ensure that our algorithm runs correctly with fair consideration of each variable, we will standardize the numeric university attributes so that they are all scaled equally.  
```{r}
corvars<- c("ExpenditurePerStudent", "RoomBoardCosts", "GraduationRate", "DonatingAlumniPercentage", "Top10Percent", "StudentFacultyRatio")
corvars <- numericvars[,corvars] 
standardized <- scale(corvars)  # scale standardizes the variables so that they are centered around 0 and vary by a standard deviation of 1 
datatable(standardized) # output the table
```

### Determining How Many Clusters to Use {.tabset}
Both the elbow plot and NbClust method indicate the 3 clusters is a good choice for the data.  The elbow plot "kinks" to indicate diminishing returns around k=3 and 8 of the k-means algorithms chose 3 clusters most often.  Although, 9 of the k-means algorithms chose 2 clusters most often, the increased explained variability in the elbow plot appears significant enough to use 3 clusters instead of 2.  Therefore, we will make our model with 3 clusters.  

#### Elbow Plot

```{r}
# explained variance function will take data and a specific number of clusters and output the corresponding variance explained
explained_variance = function(data_in, k){   
  
  set.seed(1)  # set seed for reproducibility
  kmeans_obj = kmeans(data_in, centers = k, algorithm = "Lloyd", iter.max = 30) # Running the k-means algorithm with euclidean distance
  
  # Calculate the variance accounted for by clusters:
  # var_exp = intercluster variance / total variance
  var_exp = kmeans_obj$betweenss / kmeans_obj$totss
  var_exp  
}

explained_var_list = sapply(1:20, explained_variance, data_in = standardized)  # run the explained_variance function with the numeric variable data and cluster numbers 1 through 10

elbow_data = data.frame(k = 1:20, Explained_Variance= explained_var_list)  # put explained_variance output in dataframe with corresponding k value to use for plotting

#Create a elbow chart of the output of the explained_variance function run
ggplot(elbow_data,   # create a ggplot using the elbow chart data
       aes(x = k,  # use k on the x axis and explained variance on the y axis
           y = Explained_Variance)) + 
  geom_point(size = 4) +           # set the size of the data points
  geom_line(size = 1) +            # set the thickness of the line
  ggtitle('Variance Explained by Different Cluster Numbers') +  # title the graph
  xlab('k') +   # label the x and y axes
  ylab('Inter-cluster Variance / Total Variance') + 
  theme_bw()  # use the ggplot theme black and white to display

```

The Elbow Plot graphs the explained variance of the model with different cluster numbers.  When the graph begins to plateau, this indicates that the increasing complexity is providing decreasing information, a phenomena called diminishing returns.  Therefore, we want a cluster number that provides the most explained variance before diminishing returns begin.  

#### NBClust: K by Majority Vote 

```{r}
set.seed(1)  # set starting point for reproducibility
nbclust_obj = NbClust(data = standardized, method = "kmeans")  # Use the NBClust method to run many approaches of k-means and output the most frequent cluster number chosen by each approach

freq_k = nbclust_obj$Best.nc[1,]  # subset the first row of the best.nc output which states the k chosen by each approach
freq_k = data.frame(Number_of_Clusters_Recommended = freq_k)  # convert row to a data frame so that it can be plotted by ggplot

# Plot the frequency of clusters selected by methods
ggplot(freq_k,   # creates a plot using the frequency data fame
       aes(x = Number_of_Clusters_Recommended)) +  # plots the recommended clusters on the x axis
  geom_bar() +  # makes a bar chart
  scale_x_continuous(breaks = seq(0, 15, by = 1)) +  # sets the x and y axis ticks
  scale_y_continuous(breaks = seq(0, 15, by = 1)) +
  labs(x = "Number of Clusters",  # labels the title of the plot and the axes
       y = "Number of Votes",
       title = "NBClust Cluster Analysis") + 
  theme_bw()  # use the ggplot theme black and white to display
```

The NBClust method runs a variety of approaches to the k-means clustering algorithm and returns the number of clusters that each approach chose most often to evaluate the data.  The plot above summarizes the number of approaches that chose each cluster number most often.  This method of determining cluster number is through majority vote.  

### Run K-Means Algorithm using 3 Clusters
From our 3 cluster model, it appears that the first cluster is likely the poorer quality schools with the smallest expenditure per student, graduation rate, donating alumni percentages, and percentage students in the Top 10% of their classes, and biggest student to faculty ratio. The second cluster is likely higher quality schools with the largest expenditure per student, graduation rate, donating alumni percentages, and percentage students in the Top 10% of their classes, and smallest student to faculty ratio. Finally the third cluster is more mid-range universities.  

```{r}
set.seed(1)  # sets the starting point for R to run the algorithm so that the results are reproducible
kmeans_obj = kmeans(standardized, centers = 3, # implements the k-means method with 3 centroids 
                        algorithm = "Lloyd")   # using the euchlidean distance method

kmeans_obj  # prints the result of the k-means algorithm 

head(kmeans_obj) # prints the results of each output from the k-means algorithm
```

### Modeling of Clusters {.tabset}
#### Graduation Rate vs Students in the Top 10% of Class

```{r}
clusters = as.factor(kmeans_obj$cluster)  # converts the cluster variable to factor rather than numeric so that when graphing they can be used as categories

plotting <- data.frame(corvars, tuition, clusters)  # combine the numeric variables and the salary data into a data frame 

plotting <- data.frame(plotting, College = data$College)  # combine the numeric variables and salary data with the player names column

fig1 <- plot_ly(plotting, # create a plotly graphic
               type = "scatter",  # make it a scatterplot 
               mode="markers",
               symbol = ~clusters,  # make the point shape based on the cluster column
               x = ~GraduationRate, # make x axis Games Started column
               y = ~Top10Percent, # make y axis FieldGoals column
               color = ~tuition,  # color the points based on the tuition column
               symbols = c(0,1,5),  # make the symbols, open circle, square, and triangle
               text = ~paste('College:',College,  # hover text for college and tuition
                             "Tuition:",tuition))


fig1 
```

#### Expenditure Per Student vs Student to Faculty Ratio

```{r}
fig2 <- plot_ly(plotting, # create a plotly graphic
               type = "scatter",  # make it a scatterplot 
               mode="markers",
               symbol = ~clusters,  # make the point shape based on the cluster column
               x = ~log(ExpenditurePerStudent), # make x axis Games Started column
               y = ~StudentFacultyRatio, # make y axis FieldGoals column
               color = ~tuition,  # color the points based on the tuition column
               symbols = c(0,1,5),  # make the symbols, open circle, square, and triangle
               text = ~paste('College:',College,  # hover text for college and tuition
                             "Tuition:",tuition))


fig2 
```

#### Graduation Rate vs Donating Alumni Percentage
```{r}
fig3 <- plot_ly(plotting, # create a plotly graphic
               type = "scatter",  # make it a scatterplot 
               mode="markers",
               symbol = ~clusters,  # make the point shape based on the cluster column
               x = ~GraduationRate, # make x axis Games Started column
               y = ~DonatingAlumniPercentage, # make y axis FieldGoals column
               color = ~tuition,  # color the points based on the tuition column
               symbols = c(0,1,5),  # make the symbols, open circle, square, and triangle
               text = ~paste('College:',College,  # hover text for college and tuition
                             "Tuition:",tuition))


fig3 
```

### Modeling Results 
Overall, there appear to be two universities that stand out with low tuition in the higher quality school cluster, cluster 2.  The first university is the University of North Carolina at Chapel Hill, a larger, public state school.  Particularly in the first graphic, UNC stands out as the school with the lowest tuition and the largest combination for graduation rate and percentage of students in the top 10% of their class.  The school also has a relatively low student-faculty ratio and high expenditure per student as depicted in the second graph.  The second university if Mary Baldwin University, a smaller, private school. Mary Baldwin stands out particularly in the third graphic with a high graduation rate and a high percentage of alumni who donate.  The school is also notable in the second graphic with a low student-faculty ratio and relatively high expenditure per student.  

## Evaluation

## Fairness Assessment 

## Conclusions 
- may want to use modeling results in conclusion and just have the graphs as the method results 

## Future Work 
-limits: small data size -> use more universities in US (only uses 777)




















































